---
phase: 01-engine-task-bus
plan: 03
type: execute
wave: 2
depends_on: ["01-01", "01-02"]
files_modified:
  - src/dashboard/frontend/src/pages/ChatPage.tsx
  - src/dashboard/frontend/src/components/chat/MessageList.tsx
  - src/dashboard/frontend/src/components/chat/PartRenderer.tsx
  - src/dashboard/frontend/src/components/chat/InputBar.tsx
  - src/dashboard/frontend/src/hooks/useStreaming.ts
autonomous: true

must_haves:
  truths:
    - "User can see existing messages in a chat session"
    - "User can type and send a message"
    - "Response streams progressively with structured blocks"
    - "Tool calls render as collapsible blocks with status indicators"
    - "Code blocks render with syntax highlighting"
    - "User can abort a running response"
  artifacts:
    - path: "src/dashboard/frontend/src/components/chat/MessageList.tsx"
      provides: "Scrollable message list with user/assistant grouping"
      min_lines: 60
    - path: "src/dashboard/frontend/src/components/chat/PartRenderer.tsx"
      provides: "Discriminated renderer for all Part types"
      min_lines: 100
    - path: "src/dashboard/frontend/src/components/chat/InputBar.tsx"
      provides: "Rich input bar with send, file attach placeholder, @mention placeholder"
      min_lines: 60
    - path: "src/dashboard/frontend/src/hooks/useStreaming.ts"
      provides: "SSE streaming hook with Part accumulation"
      min_lines: 50
  key_links:
    - from: "src/dashboard/frontend/src/hooks/useStreaming.ts"
      to: "backend /api/sessions/:id/prompt"
      via: "fetch with streaming body read"
      pattern: "fetch.*prompt|ReadableStream|getReader"
    - from: "src/dashboard/frontend/src/components/chat/PartRenderer.tsx"
      to: "react-markdown"
      via: "TextPart rendering with markdown"
      pattern: "ReactMarkdown|react-markdown"
    - from: "src/dashboard/frontend/src/pages/ChatPage.tsx"
      to: "src/dashboard/frontend/src/components/chat/MessageList.tsx"
      via: "MessageList component with messages prop"
      pattern: "MessageList"
---

<objective>
Build the chat interface with real-time streaming and structured message rendering.

Purpose: This is the primary interaction surface — users chat with OpenCode agents and see structured streaming responses with progressive markdown, tool call blocks, and code highlighting. Per user decision: structured streaming blocks, not raw token stream.

Output: Chat page with message list, part renderers (text/tool/code/agent), streaming hook, rich input bar.
</objective>

<execution_context>
@/Users/apple/.config/opencode/get-shit-done/workflows/execute-plan.md
@/Users/apple/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/01-engine-task-bus/01-RESEARCH.md
@.planning/phases/01-engine-task-bus/01-01-SUMMARY.md
@.planning/phases/01-engine-task-bus/01-02-SUMMARY.md
@src/dashboard/frontend/src/lib/api.ts
@src/dashboard/frontend/src/hooks/useSession.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Streaming Hook + Part Accumulator</name>
  <files>src/dashboard/frontend/src/hooks/useStreaming.ts</files>
  <action>
Create `src/dashboard/frontend/src/hooks/useStreaming.ts` — the core streaming hook that sends a prompt and accumulates parts from the SSE response.

**`useStreaming(sessionId: string)` hook:**
- State: `parts: Map<string, Part>` (keyed by part ID), `isStreaming: boolean`, `error: string | null`
- `sendPrompt(text: string)` function:
  1. Set `isStreaming = true`
  2. POST to `/api/sessions/${sessionId}/prompt` with `{ parts: [{ type: "text", text }] }`
  3. Read the response as an SSE stream using `fetch()` + `response.body.getReader()` + `TextDecoder`
  4. Parse each `data: {...}\n\n` line as a JSON event
  5. For `message.part.updated` events: merge delta into accumulated parts map
  6. For `session.error` events: set error state
  7. On stream end: set `isStreaming = false`
- `abort()` function: calls `api.abortSession(sessionId)`, sets `isStreaming = false`
- Return: `{ parts, isStreaming, error, sendPrompt, abort }`

**Part accumulation logic:**
- Each `message.part.updated` event has `{ part: { id, type, ... } }`
- If part ID is new: add to map
- If part ID exists: merge fields (text parts: append text, tool parts: update state/output)
- Text parts accumulate by appending the `text` delta field
- Tool parts update `state`, `input`, `output` fields as they arrive

**Important:** The streaming response from the backend prompt endpoint is SSE format, NOT the SDK async iterable directly. Parse `data:` lines from the fetch response stream.
  </action>
  <verify>
TypeScript compiles. Hook can be imported and called in a component without errors.
  </verify>
  <done>
useStreaming hook sends prompts, streams responses via SSE, accumulates parts by ID, handles abort. Returns parts map, streaming state, and error state.
  </done>
</task>

<task type="auto">
  <name>Task 2: Build Chat Components + Wire to ChatPage</name>
  <files>src/dashboard/frontend/src/components/chat/MessageList.tsx, src/dashboard/frontend/src/components/chat/PartRenderer.tsx, src/dashboard/frontend/src/components/chat/InputBar.tsx, src/dashboard/frontend/src/pages/ChatPage.tsx</files>
  <action>
**Create `src/dashboard/frontend/src/components/chat/PartRenderer.tsx`:**
Switch on `part.type` discriminant to render structured blocks:

- `text` → Render with `react-markdown` + `rehype-highlight` + `remark-gfm`. Wrap in a styled div. During streaming, show a blinking cursor at the end.
- `tool` → Collapsible block with: tool name as header, status badge (pending=gray, running=blue spinning, completed=green check, error=red x), input as code block (collapsed by default), output as code block (shown when completed). Use lucide-react icons.
- `step-start` / `step-finish` → Subtle divider with step label
- `agent` → Agent delegation marker with agent name badge. Styled as a distinct visual block per user decision (threaded delegation)
- `reasoning` → Collapsible "Thinking..." block with italic text, collapsed by default
- `file` → File reference with filename and diff preview (if available)
- `compaction` → Info banner: "Session compacted — context refreshed"
- Default/unknown → Render as `<pre>` with JSON.stringify fallback

**Create `src/dashboard/frontend/src/components/chat/MessageList.tsx`:**
- Takes `messages: Message[]` and `streamingParts: Map<string, Part>` props
- Groups messages by role (user vs assistant)
- User messages: right-aligned, subtle background
- Assistant messages: left-aligned, full width
- For each message, iterate over its parts and render via `PartRenderer`
- Streaming parts (from current response) render at the bottom
- Auto-scroll to bottom on new content (use `useRef` + `scrollIntoView`)
- Use `ScrollArea` from shadcn/ui for smooth scrolling

**Create `src/dashboard/frontend/src/components/chat/InputBar.tsx`:**
Per user decision: rich input bar with file attachment, @mentions, slash commands, markdown toolbar.

- Multi-line textarea that grows (min 1 row, max 6 rows)
- Send button (lucide `Send` icon) — disabled when empty or streaming
- Abort button (lucide `Square` icon) — shown only when streaming
- Placeholder buttons for: file attachment (Paperclip icon), @mention (AtSign icon), slash command (Slash icon) — these are placeholder UI for Phase 1, wired in later phases
- Keyboard: Enter to send, Shift+Enter for newline
- Props: `onSend(text: string)`, `onAbort()`, `isStreaming: boolean`

**Update `src/dashboard/frontend/src/pages/ChatPage.tsx`:**
Wire everything together:
- Left panel: session list from `useSessions()` + "New Chat" button
- Main area: `MessageList` + `InputBar`
- Use `useParams()` to get current session ID
- Use `useMessages(sessionId)` to load history
- Use `useStreaming(sessionId)` for live streaming
- On send: call `sendPrompt(text)`, on abort: call `abort()`
- Session list shows title + relative time, active session highlighted
- Empty state: "Start a new conversation" with prominent button
  </action>
  <verify>
`cd src/dashboard/frontend && npm run build` succeeds. Navigate to `/chat`, create a session, type a message, see structured streaming response.
  </verify>
  <done>
Chat page renders message history, streams new responses with structured blocks (markdown, tool calls, code), allows abort. Input bar supports send/abort with placeholder attachment buttons. Per user decisions: structured streaming blocks, rich input bar.
  </done>
</task>

</tasks>

<verification>
1. `cd src/dashboard/frontend && npx tsc --noEmit` — zero errors
2. `cd src/dashboard/frontend && npm run build` — succeeds
3. Navigate to `/chat` — sees session list and empty state
4. Click "New Chat" — creates session, navigates to it
5. Type message and send — sees structured streaming response
6. Tool calls render as collapsible blocks with status
7. Code blocks have syntax highlighting
8. Abort button stops streaming
9. Messages persist across page navigation (re-fetched from API)
</verification>

<success_criteria>
- Chat messages render with structured blocks (not raw tokens) per user decision
- Tool calls show as collapsible blocks with running/completed/error states
- Code blocks render with syntax highlighting via rehype-highlight
- Input bar supports Enter to send, Shift+Enter for newline
- Streaming can be aborted
- Session history loads on revisiting a session
</success_criteria>

<output>
After completion, create `.planning/phases/01-engine-task-bus/01-03-SUMMARY.md`
</output>
